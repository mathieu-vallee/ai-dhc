{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils import DataManager\n",
    "from Substation_real import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler_knn = PCA(n_components=4, whiten=True)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_knn = KNeighborsClassifier(algorithm='ball_tree', leaf_size=25, metric='euclidean',\n",
    "                     n_jobs=20, n_neighbors=3, p=1.2478426560306763)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler_lr = PCA(n_components=4, whiten=True)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr = LogisticRegression(C=0.3699214191568069, l1_ratio=0.5, max_iter=709, n_jobs=20,\n",
    "                   random_state=1, solver='sag', tol=0.002743766415124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_rf = MinMaxScaler(clip=True, feature_range=(-1.0, 1.0))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
    "                       criterion='entropy', max_features=0.12077862686737162,\n",
    "                       min_samples_leaf=2, n_estimators=82, n_jobs=20,\n",
    "                       random_state=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler_svc = PCA(n_components=5, whiten=True)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_svc = LinearSVC(C=1.4154375206825454, intercept_scaling=1.1127529228889177,\n",
    "          max_iter=1311, multi_class='crammer_singer', random_state=3,\n",
    "          tol=0.0003672100970153386)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler_xgb = PCA(n_components=5, whiten=True)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "              colsample_bylevel=0.9180722541805479, colsample_bynode=1,\n",
    "              colsample_bytree=0.9109072964153705, enable_categorical=False,\n",
    "              gamma=0.005048898721121109, gpu_id=-1, importance_type=None,\n",
    "              interaction_constraints='', learning_rate=0.44104052517602826,\n",
    "              max_delta_step=0, max_depth=5, min_child_weight=5, missing=np.nan,\n",
    "              monotone_constraints='()', n_estimators=2600, n_jobs=20,\n",
    "              num_parallel_tree=1, predictor='auto', random_state=4,\n",
    "              reg_alpha=0.869216551449954, reg_lambda=1.9967334510937407,\n",
    "              scale_pos_weight=1, seed=4, subsample=0.6654978224569946,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LR in that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler_lr\n",
    "model = model_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading train data and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_fault_dataset import SubstationFaultLoader\n",
    "\n",
    "loader = SubstationFaultLoader(os.path.join(DATA_ROOT, 'Substation-20221015'))\n",
    "\n",
    "train_faults = pd.read_csv(TRAIN_SPEC, index_col=0)\n",
    "data_train, metadata_train = loader.load_fault_dataset_df(list(train_faults.index.values))\n",
    "dm_train = DataManager()\n",
    "dm_train.prepare_database(data_train, metadata_train, del_cols=HIDDEN_VARS+['anomaly'])\n",
    "\n",
    "X_train, y_train = dm_train.split_X_Y_concat()\n",
    "X_train['TIN_s_K'] = 48 + 237.15\n",
    "X_train['TOUT_s_K'] = 70 + 237.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data and computing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('real/podstanica_vreme.csv', header=0, index_col=1, parse_dates=True)\n",
    "df_test = pd.DataFrame()\n",
    "df_test['TIN_p_K'] = df_raw['tnp'] + 273.15\n",
    "df_test['TOUT_p_K'] = df_raw['tpp'] + 273.15\n",
    "df_test['TIN_s_K'] = df_raw['tps'] + 273.15\n",
    "df_test['TOUT_s_K'] = df_raw['tns'] + 273.15\n",
    "df_test['DemandPower_kW'] = df_raw['qizm']\n",
    "\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(scaler.transform(X_test))\n",
    "y_test = 0 * y_pred # assuming no fault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_test,\ty_pred)\n",
    "print(\"MCC: %.3f\" % mcc)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = {'scaler': scaler, 'model': model}\n",
    "# save_object(knn, 'model_knn.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Yacine.model_evaluation_plots import *\n",
    "\n",
    "y_prob = model.predict_proba(scaler.transform(X_test))\n",
    "y_pred = alert_trigger(horizon=1, proba=y_prob[:,1], threshold=0.5)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_DTLM = (X_test['TIN_p_K'] - X_test['TOUT_s_K']) - (X_test['TOUT_p_K'] - X_test['TIN_s_K']) \\\n",
    "    / np.log((X_test['TIN_p_K'] - X_test['TOUT_s_K'])/(X_test['TOUT_p_K']-X_test['TIN_s_K']))\n",
    "UA = X_test['DemandPower_kW'] / x_DTLM\n",
    "\n",
    "UA_mean = UA.fillna(method='pad').rolling(24).mean()\n",
    "UA_mean[UA_mean<0] = 0\n",
    "UA_mean[UA_mean>7] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_var_data = pd.DataFrame(1000 * UA_mean, columns=['var'])\n",
    "\n",
    "df = pd.DataFrame({'true': y_test, 'pred' : y_pred})\n",
    "df['t_pred'] = df.loc[df['true'] == df['pred'], 'pred']\n",
    "df['f_pred'] = df.loc[df['true'] != df['pred'], 'pred']\n",
    "df.index = fault_var_data.index\n",
    "\n",
    "df_plot = pd.merge(df, fault_var_data, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(df_plot, 'resu_sst_lr.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_false_2(ax, df, legend=False, twin_legend=False):\n",
    "    ax.plot(df.index, df['true'] , label='Ground truth', color='blue')\n",
    "    ax.plot(df.index, df['t_pred'], 'x', label='Correct Fault Detection', color='green')\n",
    "    ax.plot(df.index, df['f_pred'], 'x', label='Wrong Fault Detection', color='red')\n",
    "\n",
    "    ax.set_ylabel('Classification (0: no fault, 1: fault)')\n",
    "    ax.set_xlabel('Date') \n",
    "\n",
    "    if legend:\n",
    "        ax.legend()\n",
    "\n",
    "    axtwin1 = ax.twinx()\n",
    "    axtwin1.plot(df.index, df['var'], label=fault_var_label, color='grey')\n",
    "\n",
    "    axtwin1.set_ylabel('Estimated UA [W/K]')\n",
    "\n",
    "    if twin_legend:\n",
    "        axtwin1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot1 = df_plot.loc['2017-02-01':'2017-04-30']\n",
    "df_plot2 = df_plot.loc['2018-09-01':'2019-04-30']\n",
    "df_plot3 = df_plot.loc['2019-09-01':'2020-04-30']\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(25,15))\n",
    "plot_true_false_2(ax[0], df_plot1, twin_legend=True)\n",
    "\n",
    "plot_true_false_2(ax[1], df_plot2)\n",
    "plot_true_false_2(ax[2], df_plot3, legend=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74195922b656532d49c43b3440a8d0007aa68ad14ddf08323bc8f7dc309a2fde"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ai_dhc_v2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
